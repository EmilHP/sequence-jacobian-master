{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e492e4e7d28b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mhet_block\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msimple_block\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "# model imports\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "from het_block import het\n",
    "import simple_block as sim\n",
    "from simple_block import simple\n",
    "from rouwenhorst import rouwenhorst\n",
    "import jacobian as jac\n",
    "import nonlinear\n",
    "import HANK_durables as hank\n",
    "import determinacy as det\n",
    "from scipy import optimize\n",
    "\n",
    "# DAG imports\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2-calibration\"></a>\n",
    "\n",
    "## 1. Calibrating the steady state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "household = hank.household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hank_ss(beta_guess=0.9745, r=0.03/4, sigma_N=1.0, sigma_D=1.0, delta=0.1, alpha = 6.0, vareps=10.0, tau_e = 0,  rho_e=0.9777, sigma_e=0.1928,\n",
    "            phi_pi=1.5, phi_y = 0.125, theta = 2.5, xi = 105, Ne=7, Nb=80, Nd=90,  bmax=150, dmax=135):\n",
    "    \"\"\"Solve steady state of full GE model. Calibrate beta to hit target interest rate where parameters adjust to get N=1, Y=1, Q=1\"\"\"\n",
    "\n",
    "    # a. set up grids\n",
    "    psi = 0.5 # \"bmin\":: psi*Y, Y=1\n",
    "    b_grid = utils.agrid(amax=bmax, n=Nb, amin=-psi)\n",
    "    d_grid = utils.agrid(amax=dmax, n=Nd, amin=1e-6)\n",
    "    e_grid_log, e_ergodic, Pi_e = rouwenhorst(rho_e,sigma_e,Ne)\n",
    "    e_grid = np.exp(e_grid_log) / np.sum(e_ergodic * np.exp(e_grid_log)) # normalize so E[e]=1\n",
    "    Nk = Nd # number of grid points for lagrange multiplier grid\n",
    "    kmax = 1.0 # 1 = max for lagrange mult.\n",
    "    k_grid = utils.agrid(amax=kmax,n=Nk,amin=0)\n",
    "    \n",
    "    # b. solve analytically what we can (zero inflation s.s.)\n",
    "    N = 1.0 # as psi_N = W/P_n * 1/C, psi_N found after root finding\n",
    "    Q = 1.0 # as chi = C / (C+D), chi found after root finding\n",
    "    A = 1.0/N # s.s. TFP level, set such that Y = 1\n",
    "    markup_p_ss = vareps/(vareps-1) # P mark-up\n",
    "    P = 1.0 # numeriare\n",
    "    W = (A*P)/markup_p_ss\n",
    "    Y = A*N # Y = 1\n",
    "    P_n = P # price of non-durables, follows from retailer price relation\n",
    "    P_d = P # price of durables, follows from retailer price relation\n",
    "    Div = Y - N*(W/P) # s.s. profits\n",
    "\n",
    "    # c. initialize guess for policy function iteration\n",
    "    c = (b_grid[:, np.newaxis] + d_grid)/2\n",
    "    c[c<0] = 1e-8 # assert c>0\n",
    "    d = c \n",
    "    Vb = c**(-1/sigma_N) * np.ones((e_grid.shape[0], 1, 1))\n",
    "    Vd = d**(-1/sigma_N) * np.ones((e_grid.shape[0], 1, 1))\n",
    "        \n",
    "    # d. pre-compute RHS of combined F.O.C. optimality condition\n",
    "    P_d_p = P_d/P\n",
    "    rhs = P_d_p + alpha*((d_grid[:, np.newaxis]/d_grid[np.newaxis, :]) - (1-delta)) # P_d/P + partial Psi/partial d'\n",
    "\n",
    "    # e. define residual function\n",
    "    def residual(x0):\n",
    "\n",
    "        # a. solve household ss problem\n",
    "        out = household.ss(Vd=Vd, Vb=Vb, Pi_e=Pi_e, b_grid=b_grid, dg_grid=d_grid, k_grid=k_grid, e_grid=e_grid, e_ergodic=e_ergodic, sigma_N=sigma_N, sigma_D=sigma_D,\n",
    "                                 alpha=alpha,delta=delta,r=r,Div=Div,beta=x0,Ne=Ne,Nb=Nb,Nd=Nd,Nk=Nk,P=P,P_d=P_d,P_n=P_n,W=W,N=N,tau_e=tau_e,Tax=None)\n",
    "        \n",
    "        #print(x0,[out['B'] - 0],out['DG'],out['C'])\n",
    "                                 \n",
    "        return np.array([out['B'] - 0]) # bonds are in zero net-supply\n",
    "\n",
    "    # f. solve for beta given asset market clearing\n",
    "    # i. call optimizer\n",
    "    result = optimize.root_scalar(residual,bracket=[1/(1+r)-0.05,1/(1+r)],method='bisect') # cannot go higher than 1/(1+r)\n",
    "    # ii. save result\n",
    "    beta = result.root\n",
    "    \n",
    "\n",
    "    # g. extra evaluation for reporting\n",
    "    ss = household.ss(Vd=Vd, Vb=Vb, Pi_e=Pi_e, b_grid=b_grid, dg_grid=d_grid, k_grid=k_grid, e_grid=e_grid, e_ergodic=e_ergodic, sigma_N=sigma_N, sigma_D=sigma_D,\n",
    "                                 alpha=alpha,delta=delta,r=r,Div=Div,beta=beta,Ne=Ne,Nb=Nb,Nd=Nd,Nk=Nk,P=P,P_d=P_d,P_n=P_n,W=W,N=N,tau_e=tau_e,Tax=None)\n",
    "    \n",
    "    # h. update parameters that take adjustment for hitting targets in wage schedule and combined retailer FOC equations\n",
    "    psi_N = (W/P) * (1/ss['C'])\n",
    "    chi = ss['C']/(ss['C']+ss['C_D'])\n",
    "        \n",
    "    # h. add aggregate variables\n",
    "    ss.update({'phi_pi': phi_pi, 'phi_y': phi_y, 'Y': Y, 'Y_ss': Y, 'rstar': r, 'markup_p_ss': markup_p_ss, 'markup_p': markup_p_ss, 'A': A, 'N': N, 'P': P, 'Pi': P/P, 'W': W,\n",
    "               'chi': chi, 'psi_N': psi_N, 'dg_grid': d_grid, 'Q': Q, 'P_d': P_d, 'P_n': P_n, 'Div': Div, 'vareps': vareps, 'phi_pi': phi_pi, 'phi_y': phi_y,\n",
    "               'theta': theta, 'xi': xi, 'sigma_N': sigma_N, 'sigma_D': sigma_D, 'e_ergodic': e_ergodic,'ssflag': False}) # P_d=P_n=P+eps for numerical stability\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = hank_ss()\n",
    "ss['beta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Steady-state distributions plots and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. marginal distributions\n",
    "bdmargdist = np.sum(ss['D'],axis=0) # sum out e\n",
    "dmargdist = np.sum(ss['D'],axis=1) # sum out b\n",
    "dmargcum = np.cumsum(dmargdist)\n",
    "bmargdist = np.sum(ss['D'],axis=2) # sum out d\n",
    "bmargcum = np.cumsum(bmargdist)\n",
    "e_ergodic = ss['e_ergodic']\n",
    "\n",
    "# b. cumulative distributions\n",
    "d_margdist = np.sum(bdmargdist,axis=0) # sum out b\n",
    "dmargcum = np.cumsum(d_margdist)\n",
    "b_margdist = np.sum(bdmargdist,axis=1) # sum out d\n",
    "bmargcum = np.cumsum(b_margdist)\n",
    "\n",
    "\n",
    "# b. plots \n",
    "fig1 = plt.figure()\n",
    "fig1.set_size_inches(10.5, 8.5)\n",
    "ax1 = fig1.add_subplot(221)\n",
    "ax1.plot(ss['b_grid'][:65],bmargdist[0,:65])\n",
    "ax2 = fig1.add_subplot(222)\n",
    "ax2.plot(ss['b_grid'][:65],bmargdist[4,:65])\n",
    "ax3 = fig1.add_subplot(223)\n",
    "ax3.plot(ss['b_grid'][:65],bmargdist[-1,:65])\n",
    "ax4 = fig1.add_subplot(224)\n",
    "ax4.plot(ss['e_grid'],ss['e_ergodic'])\n",
    "ax1.title.set_text('Ergodic $b$ distribution, low $e$ state')\n",
    "ax1.set_xlabel('bond holdings')\n",
    "ax1.set_ylabel('distribution weight')\n",
    "ax2.title.set_text('Ergodic $b$ distribution, median $e$ state')\n",
    "ax2.set_xlabel('bond holdings')\n",
    "ax2.set_ylabel('distribution weight')\n",
    "ax3.title.set_text('Ergodic $b$ distribution, high $e$ state')\n",
    "ax3.set_xlabel('bond holdings')\n",
    "ax3.set_ylabel('distribution weight')\n",
    "ax4.title.set_text('Ergodic productivity distribution')\n",
    "ax4.set_xlabel('productivity level')\n",
    "ax4.set_ylabel('distribution weight')\n",
    "plt.show()\n",
    "fig1.tight_layout(pad=7.0)\n",
    "fig1.savefig(\"b_dists.pdf\", bbox_inches='tight')\n",
    "\n",
    "fig2 = plt.figure()\n",
    "fig2.set_size_inches(10.5, 8.5)\n",
    "ax1 = fig2.add_subplot(221)\n",
    "ax1.plot(ss['dg_grid'][:100],dmargdist[0,:100])\n",
    "ax2 = fig2.add_subplot(222)\n",
    "ax2.plot(ss['dg_grid'][:100],dmargdist[4,:100])\n",
    "ax3 = fig2.add_subplot(223)\n",
    "ax3.plot(ss['dg_grid'][:100],dmargdist[-1,:100])\n",
    "ax4 = fig2.add_subplot(224)\n",
    "ax4.plot(ss['e_grid'],ss['e_ergodic'])\n",
    "ax1.title.set_text('Ergodic $d$ distribution, low $e$ state')\n",
    "ax1.set_xlabel('durable stock')\n",
    "ax1.set_ylabel('distribution weight')\n",
    "ax2.title.set_text('Ergodic $d$ distribution, median $e$ state')\n",
    "ax2.set_xlabel('durable stock')\n",
    "ax2.set_ylabel('distribution weight')\n",
    "ax3.set_xlabel('durable stock')\n",
    "ax3.set_ylabel('distribution weight')\n",
    "ax3.title.set_text('Ergodic $d$ distribution, high $e$ state')\n",
    "ax4.set_xlabel('durable stock')\n",
    "ax4.set_ylabel('distribution weight')\n",
    "ax4.title.set_text('Ergodic productivity distribution')\n",
    "ax4.set_xlabel('productivity level')\n",
    "ax4.set_ylabel('distribution weight')\n",
    "\n",
    "plt.show()\n",
    "fig2.tight_layout(pad=7.0)\n",
    "fig2.savefig(\"d_dists.pdf\", bbox_inches='tight')\n",
    "\n",
    "fig3 = plt.figure()\n",
    "fig3.set_size_inches(10.5, 3.5)\n",
    "ax1 = fig3.add_subplot(121)\n",
    "ax1.plot(ss['dg_grid'],dmargcum)\n",
    "ax2 = fig3.add_subplot(122)\n",
    "ax2.plot(ss['b_grid'],bmargcum)\n",
    "ax1.title.set_text('Cumulative $d$ distribution')\n",
    "ax1.set_xlabel('durable stock')\n",
    "ax2.title.set_text('Cumulative $b$ distribution')\n",
    "ax2.set_xlabel('bonds')\n",
    "\n",
    "plt.show()\n",
    "fig3.tight_layout(pad=4.0)\n",
    "fig3.savefig(\"CDFs.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. percentiles\n",
    "moms = {}\n",
    "pvec = [0.001,0.01,0.05,0.10,0.25,0.50,0.75,0.90,0.95,0.99,0.999]\n",
    "for p in pvec:\n",
    "\n",
    "    # durable\n",
    "    if p <= dmargcum[0]:\n",
    "        moms[('d',p)] = ss['dg_grid'][0]\n",
    "    else:\n",
    "        try:\n",
    "            moms[('d',p)] = np.interp(p,dmargcum,ss['dg_grid'])\n",
    "        except:\n",
    "            moms[('d',p)] = np.nan\n",
    "\n",
    "    # bonds\n",
    "    if p <= bmargcum[0]:\n",
    "        moms[('b',p)] = ss['b_grid'][0]\n",
    "    else:\n",
    "        try:\n",
    "            moms[('b',p)] = np.interp(p,bmargcum,ss['b_grid'])\n",
    "        except:\n",
    "            moms[('b',p)] = np.nan\n",
    "            \n",
    "# b. table\n",
    "print('d percentiles')\n",
    "for p in reversed(pvec):\n",
    "    print(\"%.2f\" % p,\"%.2f\" % moms['d',p])\n",
    "print('')\n",
    "print('b percentiles')\n",
    "for p in reversed(pvec):\n",
    "    print(\"%.2f\" % p,\"%.2f\" % moms['b',p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linearized dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pre-requisite price relations from retailer FOC's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the combined retailer F.O.C. we obtain $C_{d,t}(C_{d,t},Q_t)$\n",
    "$$\\left(\\frac{\\chi C_{d,t}}{(1-\\chi)C_{t}}\\right)^{\\frac{1}{\\theta}}=\\frac{1}{Q_{t}}$$\n",
    "$$\\Rightarrow C_{d,t}=C_{t}Q_{t}^{-\\theta}\\left(\\frac{1-\\chi}{\\chi}\\right)$$\n",
    "\n",
    "Thus, we obtain $P_{n,t}$ from retailer FOC wrt. $C_t$\n",
    "$$\\begin{array}{c}\n",
    "\\Rightarrow P_{t}\\left[(\\chi)^{\\frac{1}{\\theta}}{C_{t}^{-\\frac{1}{\\theta}}}\\left[(\\chi)^{\\frac{1}{\\theta}}{\\left(C_{t}\\right)^{\\frac{\\theta-1}{\\theta}}}+(1-\\chi)^{\\frac{1}{\\theta}}\\left({C_{t}}Q_{t}^{-\\theta}\\left(\\frac{1-\\chi}{\\chi}\\right)\\right)^{\\frac{\\theta-1}{\\theta}}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[(\\chi)^{\\frac{1}{\\theta}}\\left[(\\chi)^{\\frac{1}{\\theta}}+(1-\\chi)^{\\frac{1}{\\theta}}\\left(Q_{t}^{-\\theta}\\left(\\frac{1-\\chi}{\\chi}\\right)\\right)^{\\frac{\\theta-1}{\\theta}}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[(\\chi)^{\\frac{1}{\\theta}\\frac{\\theta-1}{1}}\\left[(\\chi)^{\\frac{1}{\\theta}}+(1-\\chi)^{\\frac{1}{\\theta}}\\left(Q_{t}^{-\\theta}\\left(\\frac{1-\\chi}{\\chi}\\right)\\right)^{\\frac{\\theta-1}{\\theta}}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[\\left[(\\chi)^{\\frac{1}{\\theta}\\frac{\\theta-1}{1}}(\\chi)^{\\frac{1}{\\theta}}+(\\chi)^{\\frac{1}{\\theta}\\frac{\\theta-1}{1}}(1-\\chi)^{\\frac{1}{\\theta}}\\left(Q_{t}^{-\\theta}\\left(\\frac{1-\\chi}{\\chi}\\right)\\right)^{\\frac{\\theta-1}{\\theta}}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[\\left[(\\chi)^{\\frac{1}{\\theta}+\\frac{1}{\\theta}\\frac{\\theta-1}{1}}+(\\chi)^{\\frac{1}{\\theta}\\frac{\\theta-1}{1}}(1-\\chi)^{\\frac{1}{\\theta}}Q_{t}^{1-\\theta}\\left(1-\\chi\\right)^{\\frac{\\theta-1}{\\theta}}\\chi^{\\frac{1-\\theta}{\\theta}}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[\\left[(\\chi)^{\\frac{1}{\\theta}+\\frac{1}{\\theta}\\frac{\\theta-1}{1}}+(\\chi)^{\\frac{1}{\\theta}\\frac{\\theta-1}{1}+\\frac{1-\\theta}{\\theta}}(1-\\chi)^{\\frac{1}{\\theta}+\\frac{\\theta-1}{\\theta}}Q_{t}^{1-\\theta}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[\\left[(\\chi)^{1}+{(\\chi)^{0}}(1-\\chi)^{1}Q_{t}^{1-\\theta}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow\\frac{P_{t}}{P_{n,t}}=\\left[\\chi+(1-\\chi)Q_{t}^{1-\\theta}\\right]^{\\frac{1}{1-\\theta}}\n",
    "\\end{array}$$\n",
    "\n",
    "so $P_{n,t}=\\left[\\chi+(1-\\chi)Q_{t}^{1-\\theta}\\right]^{\\frac{1}{\\theta-1}}P_{t}$\n",
    "\n",
    "which pins downs $P_{d,t}$\n",
    "$$P_{d,t}=P_{n,t}\\cdot Q_t$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Equilibrium equations neccessary to compute impulse responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} P_{n,t}=\\left[\\chi+(1-\\chi)Q_{t}^{1-\\theta}\\right]^{\\frac{1}{\\theta-1}}P_{t} \\end{equation}\n",
    "\n",
    "\\begin{equation} P_{d,t}=P_{n,t}Q_t \\end{equation}\n",
    "\n",
    "\\begin{equation} \\Pi_{t}=\\frac{P_{t}}{P_{t-1}} \\end{equation}\n",
    "\n",
    "\\begin{equation} \\mathcal{M}_{t}^{p}=\\frac{1}{\\frac{\\xi}{\\epsilon}\\left(\\Pi_{t}\\left(\\Pi_{t}-1\\right)-\\frac{1}{1+r_{t+1}}\\left(\\frac{Y_{t+1}}{Y_{t}}\\right)\\Pi_{t+1}\\left(\\Pi_{t+1}-1\\right)\\right)+\\frac{1}{\\mathcal{M}^{p}}} \\end{equation}\n",
    "\n",
    "\\begin{equation} i_{t}=r_{t}^{*}+\\phi_{\\pi}\\pi_{t}+\\phi_{y} \\hat{y}_t \\end{equation}\n",
    "\n",
    "\\begin{equation} r_{t}=\\frac{1+i_{t}}{1+\\pi_{t}}-1 \\end{equation}\n",
    "\n",
    "\\begin{equation} N_{t}=Y_{t}/A_{t} \\end{equation}\n",
    "\n",
    "\\begin{equation} W_{t}=\\frac{A_{t} P_{t}}{\\mathcal{M}_{t}^{p} } \\end{equation}\n",
    "\n",
    "\\begin{equation} Div_{t}=Y_{t}\\left(1-(\\xi/2)\\left(\\Pi_{t}-1\\right)^{2}\\right)-\\frac{W_{t}}{P_{t}}N_{t} \\end{equation}\n",
    "\n",
    "\\begin{equation} B_{t}=0 \\end{equation}\n",
    "\n",
    "\\begin{equation} P_{n,t}C_{t}+P_{n,t}Q_tC_{d,t}-P_{t}Y_{t}=0 \\end{equation}\n",
    "\n",
    "\\begin{equation} \\frac{W_{t}}{P_{t}}=\\psi_N N_{t}C_{n,t} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The endogenous variables are $U=(Y_{t},P_{t},Q_{t})$, the exogenous\n",
    "variables are $Z=(r_{t}^{*},A_{t})$. With the following targets,\n",
    "the system to be solved is given as\n",
    "\n",
    "\\begin{equation}\n",
    "H\\left(Y_{t},P_{t},Q_{t}\\right)=\\left(\\begin{array}{c}\n",
    "\\text{Bonds market clearing}\\\\\n",
    "\\text{Retailer zero-profit condition}\\\\\n",
    "\\text{Wage schedule}\n",
    "\\end{array}\\right)=\\left(\\begin{array}{c}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Denoting household solution variables as caligraphic variables for\n",
    "$\\mathcal{B},\\mathcal{D},\\mathcal{C}$, the system is explicitly\n",
    "\n",
    "\\begin{equation}\n",
    "H\\left(Y_{t},P_{t},Q_{t}\\right)=\\left(\\begin{array}{c}\n",
    "\\mathcal{B}_{t}\\\\\n",
    "P_{n,t}\\mathcal{C}_{n,t} + P_{n,t}Q_t\\mathcal{C}_{d,t} - P_t Y_t\\\\\n",
    "\\frac{W_{t}}{P_{t}}-\\psi_{N}N_{t}\\mathcal{C}_{n,t}\n",
    "\\end{array}\\right)=\\left(\\begin{array}{c}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Define simple blocks (eq. by eq.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@simple\n",
    "def prices(P,Q,chi,theta): # non-durable price from retailer FOC, durable price through Q definition\n",
    "    P_n = P*(chi + (1-chi)*Q**(1-theta))**(1/(theta-1))\n",
    "    P_d = Q*P_n\n",
    "    return P_n,P_d\n",
    "\n",
    "@simple\n",
    "def inflation(P): # inflation definition\n",
    "    Pi = P/P(-1) \n",
    "    return Pi\n",
    "\n",
    "@simple\n",
    "def markup_p(Pi,Y,xi,vareps,markup_p_ss,r): # P mark-up through Phillips curve\n",
    "    markup_p = 1/((xi/vareps)*( Pi*(Pi-1) - (1/(1+r(+1))) * (Y(+1)/Y)*Pi(+1)*(Pi(+1) - 1) ) - 1/markup_p_ss)\n",
    "    return markup_p\n",
    "\n",
    "@simple\n",
    "def taylor(rstar,Pi,Y,Y_ss,phi_pi,phi_y): # monetary policy\n",
    "    i_minus = rstar + phi_pi*np.log(Pi)# + phi_y*np.log(Y/Y_ss) # Taylor rule\n",
    "    r = (1+i_minus)/(1+np.log(Pi)) - 1 # Fisher equation\n",
    "    return r\n",
    "\n",
    "@simple\n",
    "def labor_supply(Y,A): # labor supply as a function of output and TFP\n",
    "    N = Y/A\n",
    "    return N\n",
    "\n",
    "@simple\n",
    "def wage(A,P,markup_p): # wage relation\n",
    "    W = A*P/markup_p\n",
    "    return W\n",
    "\n",
    "@simple\n",
    "def dividends(Y,W,N,P,Pi,xi): # firm profits\n",
    "    Div = Y*(1-(xi/2)*(Pi-1)**2) - (W*N)/P\n",
    "    return Div\n",
    "\n",
    "@simple\n",
    "def bond_market_clearing(B): # bond market clearing\n",
    "    bond_mkt = B\n",
    "    return bond_mkt\n",
    "\n",
    "@simple\n",
    "def zero_profit_retailer(Q,C_D,C,P,P_n,Y,delta): # retailer zero-profit cond.\n",
    "    retailer_res = P_n*C + P_n*Q*C_D - P*Y\n",
    "    return retailer_res\n",
    "\n",
    "@simple\n",
    "def DG_t(DG):\n",
    "    DG_t = DG(-1)\n",
    "    return DG_t\n",
    "\n",
    "@simple\n",
    "def wage_schedule(W,P,N,C,psi_N): # wage schedule target\n",
    "    wage_res = W/P - psi_N*N*C\n",
    "    return wage_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cut to the chase\n",
    "The surest way to obtain the general equilibrium Jacobians is to use the `get_G` convenience function. Notice the `save=True` option. This means that we're saving the HA Jacobians calculated along the way for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "T = 300\n",
    "exogenous = ['rstar', 'A']\n",
    "unknowns = ['Y','P','Q']\n",
    "targets = ['bond_mkt','retailer_res','wage_res']\n",
    "\n",
    "# general equilibrium jacobians\n",
    "block_list = [prices,inflation,markup_p,taylor,labor_supply,wage,dividends,bond_market_clearing,zero_profit_retailer,wage_schedule,DG_t,household] \n",
    "G = jac.get_G(block_list, exogenous, unknowns, targets, T, ss, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Break down `get_G`\n",
    "\n",
    "Under the hood, the very powerful `jac.get_G` performs the following steps:\n",
    " - orders the blocks so that we move forward along the model's DAG\n",
    " - computes the partial Jacobians $\\mathcal{J}^{o,i}$ from all blocks (if their Jacobian is not supplied already), only with respect to the inputs that actually change: unknowns, exogenous shocks, outputs of earlier blocks\n",
    " - forward accumulates partial Jacobians $\\mathcal{J}^{o,i}$ to form total Jacobians $\\mathbf{J}^{o,i}$\n",
    " - packs $\\mathbf{J}^{o,i}$ to form $\\mathbf{H_U}$ and $\\mathbf{H_Z}$\n",
    " - solves for the GE Jacobians for unknowns $\\mathbf{G_U} = \\mathbf{H_U}^{-1}\\mathbf{H_Z}$\n",
    " - forward accumulates GE Jacobians to obtain $\\mathbf{G}$ for other endogenous variables \n",
    " \n",
    "Let's take a closer look at each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Topological sort and partial Jacobians\n",
    "By looking at the inputs and outputs of each block, we can order them so that we only move forward on the DAG (this is called a **topological sort**). Knowing the DAG is a prerequisite for all that follows, and also allows us to avoid wasteful Jacobian calculations: we only need Jacobians with respect to unknowns, exogenous, and outputs of earlier blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curlyJs, required = jac.curlyJ_sorted(block_list, unknowns+exogenous, ss, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first output `curlyJs` is a list of nested dictionaries. Each entry in the list contains all the necessary Jacobians for the corresponding block. Blocks are ordered according to the topological sort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(curlyJs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a simple block, the Jacobians are represented as a instances of the `SimpleSparse` class. Note that `jac.curlyJ_sorted` correctly determined that it is not necessary to differentiate with respect to the Taylor rule parameter $\\phi$ (if we wanted to consider shocks to this parameter, we'd just have to include it among the exogenous inputs.)\n",
    "\n",
    "The second output `required` is a set of extra variables (not unknowns and exogenous) that we have to differentiate with respect to, because they are outputs of some blocks and inputs of others. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(required)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Compose Jacobians along the DAG\n",
    "\n",
    "First, we apply the chain rule by using `jac.forward_accumulate`. This gives the $T \\times T$ building blocks of the $H_U$ and $H_Z$ that relate targets to unknowns and exogenous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_curlyH_U = jac.forward_accumulate(curlyJs, unknowns, targets, required)\n",
    "J_curlyH_Z = jac.forward_accumulate(curlyJs, exogenous, targets, required)\n",
    "print(J_curlyH_U.keys())\n",
    "print(J_curlyH_U['bond_mkt'].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just have to pack them into two (big) matrices. These capture (to first order) the implicit relationship between unknowns, i.e. that the targets of the DAG evaluate to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H_U = jac.pack_jacobians(J_curlyH_U, unknowns, targets, T)\n",
    "H_Z = jac.pack_jacobians(J_curlyH_Z, exogenous, targets, T)\n",
    "print(H_U.shape)\n",
    "print(H_Z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: General equilibrium Jacobians\n",
    "First we can get the response of unknowns directly by the implicit function theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_U = jac.unpack_jacobians(-np.linalg.solve(H_U, H_Z), exogenous, unknowns, T)\n",
    "print(G_U.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the rest can be obtained by forward accumulation that accounts for the direct and indirect effects alike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curlyJs = [G_U] + curlyJs\n",
    "outputs = set().union(*(curlyJ.keys() for curlyJ in curlyJs)) - set(targets)\n",
    "\n",
    "G2 = jac.forward_accumulate(curlyJs, exogenous, outputs, required | set(unknowns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Results\n",
    "First let's check that we have correctly reconstructed the steps of `jac.get_G`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in G:\n",
    "    for i in G[o]:\n",
    "        assert np.allclose(G[o][i], G2[o][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider 20 basis point monetary policy shocks with different persistences and plot the response of inflation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['Y']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'Y response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['P']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'P response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['P_n']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'Pn response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['P_d']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'Pd response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['Q']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'Q response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['C']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'C response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['DG']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'D response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['N']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'N response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['W']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'W response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['markup_p']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'mark-up response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['r']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'r response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['Pi']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'Pi response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
