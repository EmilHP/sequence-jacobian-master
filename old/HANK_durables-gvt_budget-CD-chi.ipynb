{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model imports\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "from het_block import het\n",
    "import simple_block as sim\n",
    "from simple_block import simple\n",
    "from rouwenhorst import rouwenhorst\n",
    "import jacobian as jac\n",
    "import nonlinear\n",
    "import HANK_durables as hank\n",
    "import determinacy as det\n",
    "from scipy import optimize\n",
    "import Monte_Carlo\n",
    "\n",
    "# DAG imports\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import rc\n",
    "rc('font',**{'family':'sans-serif','sans-serif':['Helvetica']})\n",
    "## for Palatino and other serif fonts use:\n",
    "#rc('font',**{'family':'serif','serif':['Palatino']})\n",
    "rc('text', usetex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"2-calibration\"></a>\n",
    "\n",
    "## 1. Calibrating the steady state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "household = hank.household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hank_ss(Bg_Y=0.26,beta_guess=0.9745, r=0.03/4, sigma_N=1.0, sigma_D=2.0, delta=0.1, alpha = 10.0, vareps=10.0, tau_e = 1,  rho_e=0.9777, sigma_e=0.1928,\n",
    "            phi_pi=1.5, phi_y = 0.125, theta = 1.001, xi = 105, Ne=7, Nb=80, Nd=90,  bmax=200, dmax=135):\n",
    "    \"\"\"Solve steady state of full GE model. Calibrate beta to hit target interest rate where parameters adjust to get N=1, Y=1, Q=1\"\"\"\n",
    "\n",
    "    # a. set up grids\n",
    "    psi = 0.5 # \"bmin\":: psi*Y, Y=1\n",
    "    b_grid = utils.agrid(amax=bmax, n=Nb, amin=-psi)\n",
    "    d_grid = utils.agrid(amax=dmax, n=Nd, amin=1e-6)\n",
    "    e_grid_log, e_ergodic, Pi_e = rouwenhorst(rho_e,sigma_e,Ne)\n",
    "    e_grid = np.exp(e_grid_log) / np.sum(e_ergodic * np.exp(e_grid_log)) # normalize so E[e]=1\n",
    "    Nk = Nd # number of grid points for lagrange multiplier grid\n",
    "    kmax = 1.0 # 1 = max for lagrange mult.\n",
    "    k_grid = utils.agrid(amax=kmax,n=Nk,amin=0)\n",
    "     \n",
    "    # b. solve analytically what we can (zero inflation s.s.)\n",
    "    N = 1.0 # as psi_N = W/P_n * 1/C, psi_N found after root finding\n",
    "    Q = 1.0 # as chi = C / (C+D), chi found after root finding\n",
    "    A = 1.0/N # s.s. TFP level, set such that Y = 1\n",
    "    markup_p_ss = vareps/(vareps-1) # P mark-up\n",
    "    P = 1.0 # numeriare\n",
    "    W = (A*P)/markup_p_ss\n",
    "    Y = A*N # Y = 1\n",
    "    P_n = P # price of non-durables, follows from retailer price relation\n",
    "    P_d = P # price of durables, follows from retailer price relation\n",
    "    Div = Y - N*(W/P) # s.s. profits\n",
    "    Bg = Bg_Y*Y\n",
    "    Tax = r*Bg\n",
    "    chi = 0.04711 # McKay Wieland \n",
    "    \n",
    "    #B_y moms['B_demand'] / (4*moms['Y'])\n",
    "\n",
    "    # c. initialize guess for policy function iteration\n",
    "    c = (b_grid[:, np.newaxis] + d_grid)/2\n",
    "    c[c<0] = 1e-8 # assert c>0\n",
    "    d = c \n",
    "    Vb = c**(-1/sigma_N) * np.ones((e_grid.shape[0], 1, 1))\n",
    "    Vd = d**(-1/sigma_N) * np.ones((e_grid.shape[0], 1, 1))\n",
    "        \n",
    "    # d. pre-compute RHS of combined F.O.C. optimality condition\n",
    "    P_d_p = P_d/P\n",
    "    rhs = P_d_p + alpha*((d_grid[:, np.newaxis]/d_grid[np.newaxis, :]) - (1-delta)) # P_d/P + partial Psi/partial d'\n",
    "\n",
    "    # e. define residual function\n",
    "    \n",
    "    def residual(x0,theta,P,chi,r):\n",
    "        \n",
    "        # assert bounds on beta for stability\n",
    "        if x0[0] > 0.99:\n",
    "            x0[0] = 1/(1+r)\n",
    "        if x0[0] < 0.92:\n",
    "            x0[0] = 0.92    \n",
    "        \n",
    "        if x0[1]<0:\n",
    "            x0[1]=0.2\n",
    "        if x0[1]>1.02:\n",
    "            x0[1]=1.02\n",
    "        # prices\n",
    "        Q = x0[1]\n",
    "        P_n = P*(chi + (1-chi)*Q**(1-theta))**(1/(theta-1))\n",
    "        P_d = P_n*Q\n",
    "        print(x0[0],x0[1],P_n,P_d)\n",
    "        out = household.ss(Vd=Vd, Vb=Vb, Pi_e=Pi_e, b_grid=b_grid, dg_grid=d_grid, k_grid=k_grid, e_grid=e_grid, e_ergodic=e_ergodic, sigma_N=sigma_N, sigma_D=sigma_D,\n",
    "                                 alpha=alpha,delta=delta,r=r,Div=Div,beta=x0[0],Ne=Ne,Nb=Nb,Nd=Nd,Nk=Nk,P=P,P_d=P_d,P_n=P_n,W=W,N=N,tau_e=tau_e,Tax=Tax)\n",
    "        \n",
    "        print(out['B'] - Bg,P_n*out['C'] + P_n*Q*out['C_D'] - P*Y)\n",
    "        \n",
    "        return np.array([out['B'] - Bg, P_n*out['C'] + P_n*Q*out['C_D'] - P*Y])\n",
    "\n",
    "\n",
    "    # f. solve for beta given asset market clearing\n",
    "    # i. call optimizer\n",
    "    result = optimize.root(residual, np.array([0.974,1.01]), method='hybr',args=(theta,P,chi,r)) # have to start near solution\n",
    "    # ii. save results\n",
    "    beta = result.x[0]\n",
    "    Q = result.x[1]\n",
    "    P_n = P*(chi + (1-chi)*Q**(1-theta))**(1/(theta-1))\n",
    "    P_d = P_n*Q\n",
    "\n",
    "    # g. extra evaluation for reporting\n",
    "    ss = household.ss(Vd=Vd, Vb=Vb, Pi_e=Pi_e, b_grid=b_grid, dg_grid=d_grid, k_grid=k_grid, e_grid=e_grid, e_ergodic=e_ergodic, sigma_N=sigma_N, sigma_D=sigma_D,\n",
    "                                 alpha=alpha,delta=delta,r=r,Div=Div,beta=beta,Ne=Ne,Nb=Nb,Nd=Nd,Nk=Nk,P=P,P_d=P_d,P_n=P_n,W=W,N=N,tau_e=tau_e,Tax=Tax)\n",
    "    \n",
    "    # h. update parameters that take adjustment for hitting targets in wage schedule and combined retailer FOC equations\n",
    "    psi_N = (W/P) * (1/ss['C'])\n",
    "        \n",
    "    # h. add aggregate variables\n",
    "    ss.update({'phi_pi': phi_pi, 'phi_y': phi_y, 'Y': Y, 'Y_ss': Y, 'rstar': r, 'markup_p_ss': markup_p_ss, 'markup_p': markup_p_ss, 'A': A, 'Bg': Bg, 'N': N, 'P': P, 'Pi': P/P, 'W': W,\n",
    "               'chi': chi, 'psi_N': psi_N, 'dg_grid': d_grid, 'Q': Q, 'P_d': P_d, 'P_n': P_n, 'Div': Div, 'vareps': vareps, 'phi_pi': phi_pi, 'phi_y': phi_y,\n",
    "               'theta': theta, 'xi': xi, 'sigma_N': sigma_N, 'sigma_D': sigma_D, 'e_ergodic': e_ergodic,'ssflag': False}) # P_d=P_n=P+eps for numerical stability\n",
    "    return ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.974 1.01 0.9905632397971196 1.0004688721950907\n",
      "2.636686407316616 -0.2232431353544777\n",
      "0.974 1.01 0.9905632397971196 1.0004688721950907\n",
      "2.636686407316616 -0.2232431353544777\n",
      "0.974 1.01 0.9905632397971196 1.0004688721950907\n",
      "2.636686407316616 -0.2232431353544777\n",
      "0.974000014513731 1.01 0.9905632397971196 1.0004688721950907\n",
      "2.6366991128882384 -0.22324305953575374\n",
      "0.974 1.010000015050173 0.9905632257318933 1.00046887289736\n",
      "2.6366985142246264 -0.2232430629837714\n",
      "0.92 1.02 0.9813072018334881 1.000933345870158\n",
      "-0.7599990157101137 -0.2100198945286298\n",
      "0.92 1.02 0.9813072018334881 1.000933345870158\n",
      "-0.7599990157101137 -0.2100198945286298\n",
      "0.9925558312655086 0.2 4.635181718856445 0.927036343771289\n",
      "No convergence of policy functions after 5000 backward iterations!\n",
      "-0.7600000000000149 -0.02762862703036084\n",
      "0.9925558312655086 0.2 4.635181718856445 0.927036343771289\n",
      "No convergence of policy functions after 5000 backward iterations!\n",
      "-0.7600000000000149 -0.02762862703036084\n",
      "0.9925558312655086 0.20000000298023224 4.635181653035088 0.9270363444209353\n",
      "No convergence of policy functions after 5000 backward iterations!\n",
      "-0.7600000000000163 -0.027628626392573463\n",
      "0.9925558312655086 0.32909411852294956 2.883718522697073 0.9490148052952956\n",
      "No convergence of policy functions after 5000 backward iterations!\n",
      "-0.7600000000000154 -0.022011474844677248\n",
      "0.9925558312655086 0.534786339253222 1.815591275117257 0.9709534116000473\n",
      "-0.7600000000000151 -0.03876999888148336\n",
      "0.92 0.2899416916841567 3.2536716510538435 0.9433750626913345\n",
      "No convergence of policy functions after 5000 backward iterations!\n",
      "-0.7600000000000166 -0.0134803906860812\n",
      "0.92 0.19489090552182303 4.750907371041096 0.9259086395925029\n",
      "No convergence of policy functions after 5000 backward iterations!\n",
      "-0.7600000000000129 -0.03199769691321841\n",
      "0.9925558312655086 0.35718744992571533 2.6671723271179877 0.9526804820357099\n",
      "No convergence of policy functions after 5000 backward iterations!\n",
      "-0.7600000000000164 -0.02239963328531347\n",
      "0.9200000137090684 0.2899416916841567 3.2536716510538435 0.9433750626913345\n",
      "No convergence of policy functions after 5000 backward iterations!\n",
      "-0.7600000000000157 -0.013480389827548067\n",
      "0.92 0.28994169600462455 3.2536716048514234 0.9433750633527103\n",
      "No convergence of policy functions after 5000 backward iterations!\n",
      "-0.7600000000000147 -0.013480389884432564\n",
      "0.92 1.02 0.9813072018334881 1.000933345870158\n",
      "-0.7599990157101137 -0.2100198945286298\n",
      "0.92 1.02 0.9813072018334881 1.000933345870158\n",
      "-0.7599990157101137 -0.2100198945286298\n",
      "0.92 1.02 0.9813072018334881 1.000933345870158\n",
      "-0.7599990157101137 -0.2100198945286298\n",
      "0.9751527968641276 0.9258997173765982 1.0761205724930156 0.9963797339344261\n",
      "-0.7599999967959732 -0.18571779704380287\n",
      "0.92 0.06350426438594539 13.831560097318075 0.8783630492901796\n",
      "No convergence of policy functions after 5000 backward iterations!\n",
      "-0.7600000000000166 -0.08597757358211933\n",
      "No convergence of policy functions after 5000 backward iterations!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = hank_ss()\n",
    "ss['beta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Steady-state distributions plots and tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. marginal distributions\n",
    "bdmargdist = np.sum(ss['D'],axis=0) # sum out e\n",
    "dmargdist = np.sum(ss['D'],axis=1) # sum out b\n",
    "dmargcum = np.cumsum(dmargdist)\n",
    "bmargdist = np.sum(ss['D'],axis=2) # sum out d\n",
    "bmargcum = np.cumsum(bmargdist)\n",
    "e_ergodic = ss['e_ergodic']\n",
    "\n",
    "# b. cumulative distributions\n",
    "d_margdist = np.sum(bdmargdist,axis=0) # sum out b\n",
    "dmargcum = np.cumsum(d_margdist)\n",
    "b_margdist = np.sum(bdmargdist,axis=1) # sum out d\n",
    "bmargcum = np.cumsum(b_margdist)\n",
    "\n",
    "bmargcumfrac = np.cumsum(b_margdist*ss['b_grid']) \n",
    "bmargcumfrac /= bmargcumfrac[-1]\n",
    "\n",
    "dmargcumfrac = np.cumsum(d_margdist*ss['dg_grid']) \n",
    "dmargcumfrac /= dmargcumfrac[-1]\n",
    "\n",
    "\n",
    "# b. plots \n",
    "fig1 = plt.figure()\n",
    "fig1.set_size_inches(10.5, 8.5)\n",
    "ax1 = fig1.add_subplot(221)\n",
    "ax1.plot(ss['b_grid'][:],bmargdist[0,:])\n",
    "ax2 = fig1.add_subplot(222)\n",
    "ax2.plot(ss['b_grid'][:],bmargdist[4,:])\n",
    "ax3 = fig1.add_subplot(223)\n",
    "ax3.plot(ss['b_grid'][:],bmargdist[-1,:])\n",
    "ax4 = fig1.add_subplot(224)\n",
    "ax4.plot(ss['e_grid'],ss['e_ergodic'])\n",
    "ax1.title.set_text('Ergodic $b$ distribution, low $e$ state')\n",
    "ax1.set_xlabel('bond holdings')\n",
    "ax1.set_ylabel('distribution weight')\n",
    "ax2.title.set_text('Ergodic $b$ distribution, median $e$ state')\n",
    "ax2.set_xlabel('bond holdings')\n",
    "ax2.set_ylabel('distribution weight')\n",
    "ax3.title.set_text('Ergodic $b$ distribution, high $e$ state')\n",
    "ax3.set_xlabel('bond holdings')\n",
    "ax3.set_ylabel('distribution weight')\n",
    "ax4.title.set_text('Ergodic productivity distribution')\n",
    "ax4.set_xlabel('productivity level')\n",
    "ax4.set_ylabel('distribution weight')\n",
    "plt.show()\n",
    "fig1.tight_layout(pad=7.0)\n",
    "fig1.savefig(\"b_dists.pdf\", bbox_inches='tight')\n",
    "\n",
    "fig2 = plt.figure()\n",
    "fig2.set_size_inches(10.5, 8.5)\n",
    "ax1 = fig2.add_subplot(221)\n",
    "ax1.plot(ss['dg_grid'][:100],dmargdist[0,:100])\n",
    "ax2 = fig2.add_subplot(222)\n",
    "ax2.plot(ss['dg_grid'][:100],dmargdist[4,:100])\n",
    "ax3 = fig2.add_subplot(223)\n",
    "ax3.plot(ss['dg_grid'][:100],dmargdist[-1,:100])\n",
    "ax4 = fig2.add_subplot(224)\n",
    "ax4.plot(ss['e_grid'],ss['e_ergodic'])\n",
    "ax1.title.set_text('Ergodic $d$ distribution, low $e$ state')\n",
    "ax1.set_xlabel('durable stock')\n",
    "ax1.set_ylabel('distribution weight')\n",
    "ax2.title.set_text('Ergodic $d$ distribution, median $e$ state')\n",
    "ax2.set_xlabel('durable stock')\n",
    "ax2.set_ylabel('distribution weight')\n",
    "ax3.set_xlabel('durable stock')\n",
    "ax3.set_ylabel('distribution weight')\n",
    "ax3.title.set_text('Ergodic $d$ distribution, high $e$ state')\n",
    "ax4.set_xlabel('durable stock')\n",
    "ax4.set_ylabel('distribution weight')\n",
    "ax4.title.set_text('Ergodic productivity distribution')\n",
    "ax4.set_xlabel('productivity level')\n",
    "ax4.set_ylabel('distribution weight')\n",
    "\n",
    "plt.show()\n",
    "fig2.tight_layout(pad=7.0)\n",
    "fig2.savefig(\"d_dists.pdf\", bbox_inches='tight')\n",
    "\n",
    "fig3 = plt.figure()\n",
    "fig3.set_size_inches(10.5, 3.5)\n",
    "ax1 = fig3.add_subplot(121)\n",
    "ax1.plot(ss['dg_grid'],dmargcum)\n",
    "ax2 = fig3.add_subplot(122)\n",
    "ax2.plot(ss['b_grid'],bmargcum)\n",
    "ax1.title.set_text('Cumulative $d$ distribution')\n",
    "ax1.set_xlabel('durable stock')\n",
    "ax2.title.set_text('Cumulative $b$ distribution')\n",
    "ax2.set_xlabel('bonds')\n",
    "\n",
    "plt.show()\n",
    "fig3.tight_layout(pad=4.0)\n",
    "fig3.savefig(\"CDFs.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simT = 3000\n",
    "#simN = 2000\n",
    "#b_policy = ss['b']\n",
    "#d_policy = ss['dg']\n",
    "#c_policy = ss['c']\n",
    "#e_grid = ss['e_grid']\n",
    "#d_grid = ss['dg_grid']\n",
    "#b_grid = ss['b_grid']\n",
    "#e_ergodic = ss['e_ergodic']\n",
    "#Pi_e = ss['Pi_e']\n",
    "\n",
    "#sim_b,sim_d,sim_c = Monte_Carlo.steady_state_MC(simT,simN,b_policy,d_policy,c_policy,e_grid,b_grid,d_grid,e_ergodic,Pi_e)\n",
    "\n",
    "#sim_d_c = sim_d[1000:,:]/sim_c[1000:,:]\n",
    "#skewness_d_c = 3*(np.mean(sim_d_c) - np.median(sim_d_c))/np.std(sim_d_c) #0.4627878092589748 #0.4930580812805126 # 0.5322452262264995\n",
    "#print(f\"Skewness D/C: {skewness_d_c:.3f}\")\n",
    "\n",
    "#x = sim_d_c\n",
    "#hist, bins = np.histogram(x, bins=100)\n",
    "#width = 0.7 * (bins[1] - bins[0])\n",
    "#center = (bins[:-1] + bins[1:]) / 2\n",
    "#plt.bar(center, hist, align='center', width=width)\n",
    "#plt.xlabel('D/C')\n",
    "#plt.ylabel('Count')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. percentiles\n",
    "moms = {}\n",
    "pvec = [0.001,0.01,0.05,0.10,0.25,0.50,0.75,0.90,0.95,0.99,0.999]\n",
    "for p in pvec:\n",
    "\n",
    "    # durable\n",
    "    if p <= dmargcum[0]:\n",
    "        moms[('d',p)] = ss['dg_grid'][0]\n",
    "    else:\n",
    "        try:\n",
    "            moms[('d',p)] = np.interp(p,dmargcum,ss['dg_grid'])\n",
    "        except:\n",
    "            moms[('d',p)] = np.nan\n",
    "\n",
    "    # bonds\n",
    "    if p <= bmargcum[0]:\n",
    "        moms[('b',p)] = ss['b_grid'][0]\n",
    "    else:\n",
    "        try:\n",
    "            moms[('b',p)] = np.interp(p,bmargcum,ss['b_grid'])\n",
    "        except:\n",
    "            moms[('b',p)] = np.nan\n",
    "            \n",
    "# b. table\n",
    "print('d percentiles')\n",
    "for p in reversed(pvec):\n",
    "    print(\"%.3f\" % p,\"%.2f\" % moms['d',p])\n",
    "print('')\n",
    "print('b percentiles')\n",
    "for p in reversed(pvec):\n",
    "    print(\"%.3f\" % p,\"%.2f\" % moms['b',p])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linearized dynamics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Pre-requisite price relations from retailer FOC's"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the combined retailer F.O.C. we obtain $C_{d,t}(C_{d,t},Q_t)$\n",
    "$$\\left(\\frac{\\chi C_{d,t}}{(1-\\chi)C_{t}}\\right)^{\\frac{1}{\\theta}}=\\frac{1}{Q_{t}}$$\n",
    "$$\\Rightarrow C_{d,t}=C_{t}Q_{t}^{-\\theta}\\left(\\frac{1-\\chi}{\\chi}\\right)$$\n",
    "\n",
    "Thus, we obtain $P_{n,t}$ from retailer FOC wrt. $C_t$\n",
    "$$\\begin{array}{c}\n",
    "\\Rightarrow P_{t}\\left[(\\chi)^{\\frac{1}{\\theta}}{C_{t}^{-\\frac{1}{\\theta}}}\\left[(\\chi)^{\\frac{1}{\\theta}}{\\left(C_{t}\\right)^{\\frac{\\theta-1}{\\theta}}}+(1-\\chi)^{\\frac{1}{\\theta}}\\left({C_{t}}Q_{t}^{-\\theta}\\left(\\frac{1-\\chi}{\\chi}\\right)\\right)^{\\frac{\\theta-1}{\\theta}}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[(\\chi)^{\\frac{1}{\\theta}}\\left[(\\chi)^{\\frac{1}{\\theta}}+(1-\\chi)^{\\frac{1}{\\theta}}\\left(Q_{t}^{-\\theta}\\left(\\frac{1-\\chi}{\\chi}\\right)\\right)^{\\frac{\\theta-1}{\\theta}}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[(\\chi)^{\\frac{1}{\\theta}\\frac{\\theta-1}{1}}\\left[(\\chi)^{\\frac{1}{\\theta}}+(1-\\chi)^{\\frac{1}{\\theta}}\\left(Q_{t}^{-\\theta}\\left(\\frac{1-\\chi}{\\chi}\\right)\\right)^{\\frac{\\theta-1}{\\theta}}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[\\left[(\\chi)^{\\frac{1}{\\theta}\\frac{\\theta-1}{1}}(\\chi)^{\\frac{1}{\\theta}}+(\\chi)^{\\frac{1}{\\theta}\\frac{\\theta-1}{1}}(1-\\chi)^{\\frac{1}{\\theta}}\\left(Q_{t}^{-\\theta}\\left(\\frac{1-\\chi}{\\chi}\\right)\\right)^{\\frac{\\theta-1}{\\theta}}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[\\left[(\\chi)^{\\frac{1}{\\theta}+\\frac{1}{\\theta}\\frac{\\theta-1}{1}}+(\\chi)^{\\frac{1}{\\theta}\\frac{\\theta-1}{1}}(1-\\chi)^{\\frac{1}{\\theta}}Q_{t}^{1-\\theta}\\left(1-\\chi\\right)^{\\frac{\\theta-1}{\\theta}}\\chi^{\\frac{1-\\theta}{\\theta}}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[\\left[(\\chi)^{\\frac{1}{\\theta}+\\frac{1}{\\theta}\\frac{\\theta-1}{1}}+(\\chi)^{\\frac{1}{\\theta}\\frac{\\theta-1}{1}+\\frac{1-\\theta}{\\theta}}(1-\\chi)^{\\frac{1}{\\theta}+\\frac{\\theta-1}{\\theta}}Q_{t}^{1-\\theta}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow P_{t}\\left[\\left[(\\chi)^{1}+{(\\chi)^{0}}(1-\\chi)^{1}Q_{t}^{1-\\theta}\\right]^{\\frac{1}{\\theta-1}}\\right]=P_{n,t}\\\\\n",
    "\\Rightarrow\\frac{P_{t}}{P_{n,t}}=\\left[\\chi+(1-\\chi)Q_{t}^{1-\\theta}\\right]^{\\frac{1}{1-\\theta}}\n",
    "\\end{array}$$\n",
    "\n",
    "so $P_{n,t}=\\left[\\chi+(1-\\chi)Q_{t}^{1-\\theta}\\right]^{\\frac{1}{\\theta-1}}P_{t}$\n",
    "\n",
    "which pins downs $P_{d,t}$\n",
    "$$P_{d,t}=P_{n,t}\\cdot Q_t$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Equilibrium equations neccessary to compute impulse responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation} P_{n,t}=\\left[\\chi+(1-\\chi)Q_{t}^{1-\\theta}\\right]^{\\frac{1}{\\theta-1}}P_{t} \\end{equation}\n",
    "\n",
    "\\begin{equation} P_{d,t}=P_{n,t}Q_t \\end{equation}\n",
    "\n",
    "\\begin{equation} \\Pi_{t}=\\frac{P_{t}}{P_{t-1}} \\end{equation}\n",
    "\n",
    "\\begin{equation} \\mathcal{M}_{t}^{p}=\\frac{1}{\\frac{\\xi}{\\epsilon}\\left(\\Pi_{t}\\left(\\Pi_{t}-1\\right)-\\frac{1}{1+r_{t+1}}\\left(\\frac{Y_{t+1}}{Y_{t}}\\right)\\Pi_{t+1}\\left(\\Pi_{t+1}-1\\right)\\right)+\\frac{1}{\\mathcal{M}^{p}}} \\end{equation}\n",
    "\n",
    "\\begin{equation} i_{t}=r_{t}^{*}+\\phi_{\\pi}\\pi_{t}+\\phi_{y} \\hat{y}_t \\end{equation}\n",
    "\n",
    "\\begin{equation} r_{t}=\\frac{1+i_{t}}{1+\\pi_{t}}-1 \\end{equation}\n",
    "\n",
    "\\begin{equation} N_{t}=Y_{t}/A_{t} \\end{equation}\n",
    "\n",
    "\\begin{equation} W_{t}=\\frac{A_{t} P_{t}}{\\mathcal{M}_{t}^{p} } \\end{equation}\n",
    "\n",
    "\\begin{equation} Div_{t}=Y_{t}\\left(1-(\\xi/2)\\left(\\Pi_{t}-1\\right)^{2}\\right)-\\frac{W_{t}}{P_{t}}N_{t} \\end{equation}\n",
    "\n",
    "\\begin{equation} B_{t}=0 \\end{equation}\n",
    "\n",
    "\\begin{equation} P_{n,t}C_{t}+P_{n,t}Q_tC_{d,t}-P_{t}Y_{t}=0 \\end{equation}\n",
    "\n",
    "\\begin{equation} \\frac{W_{t}}{P_{t}}=\\psi_N N_{t}C_{n,t} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The endogenous variables are $U=(Y_{t},P_{t},Q_{t})$, the exogenous\n",
    "variables are $Z=(r_{t}^{*},A_{t})$. With the following targets,\n",
    "the system to be solved is given as\n",
    "\n",
    "\\begin{equation}\n",
    "H\\left(Y_{t},P_{t},Q_{t}\\right)=\\left(\\begin{array}{c}\n",
    "\\text{Bonds market clearing}\\\\\n",
    "\\text{Retailer zero-profit condition}\\\\\n",
    "\\text{Wage schedule}\n",
    "\\end{array}\\right)=\\left(\\begin{array}{c}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "Denoting household solution variables as caligraphic variables for\n",
    "$\\mathcal{B},\\mathcal{D},\\mathcal{C}$, the system is explicitly\n",
    "\n",
    "\\begin{equation}\n",
    "H\\left(Y_{t},P_{t},Q_{t}\\right)=\\left(\\begin{array}{c}\n",
    "\\mathcal{B}_{t}\\\\\n",
    "P_{n,t}\\mathcal{C}_{n,t} + P_{n,t}Q_t\\mathcal{C}_{d,t} - P_t Y_t\\\\\n",
    "\\frac{W_{t}}{P_{t}}-\\psi_{N}N_{t}\\mathcal{C}_{n,t}\n",
    "\\end{array}\\right)=\\left(\\begin{array}{c}\n",
    "0\\\\\n",
    "0\\\\\n",
    "0\n",
    "\\end{array}\\right)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Define simple blocks (eq. by eq.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@simple\n",
    "def prices(P,Q,chi,theta): # non-durable price from retailer FOC, durable price through Q definition\n",
    "    P_n = P*(chi + (1-chi)*Q**(1-theta))**(1/(theta-1))\n",
    "    P_d = Q*P_n\n",
    "    return P_n,P_d\n",
    "\n",
    "@simple\n",
    "def inflation(P): # inflation definition\n",
    "    Pi = P/P(-1) \n",
    "    return Pi\n",
    "\n",
    "@simple\n",
    "def markup_p(Pi,Y,xi,vareps,markup_p_ss,r): # P mark-up through Phillips curve\n",
    "    markup_p = 1/((xi/vareps)*( Pi*(Pi-1) - (1/(1+r(+1))) * (Y(+1)/Y)*Pi(+1)*(Pi(+1) - 1) ) - 1/markup_p_ss)\n",
    "    return markup_p\n",
    "\n",
    "@simple\n",
    "def taylor(rstar,Pi,Y,Y_ss,phi_pi,phi_y): # monetary policy\n",
    "    i_minus = rstar + phi_pi*np.log(Pi)# + phi_y*np.log(Y/Y_ss) # Taylor rule\n",
    "    r = (1+i_minus)/(1+np.log(Pi)) - 1 # Fisher equation\n",
    "    return r\n",
    "\n",
    "@simple\n",
    "def labor_supply(Y,A): # labor supply as a function of output and TFP\n",
    "    N = Y/A\n",
    "    return N\n",
    "\n",
    "@simple\n",
    "def wage(A,P,markup_p): # wage relation\n",
    "    W = A*P/markup_p\n",
    "    return W\n",
    "\n",
    "@simple\n",
    "def dividends(Y,W,N,P,Pi,xi): # firm profits\n",
    "    Div = Y*(1-(xi/2)*(Pi-1)**2) - (W*N)/P\n",
    "    return Div\n",
    "\n",
    "@simple\n",
    "def bond_market_clearing(B,Bg): # bond market clearing\n",
    "    bond_mkt = B - Bg\n",
    "    return bond_mkt\n",
    "\n",
    "@simple\n",
    "def zero_profit_retailer(Q,C_D,C,P,P_n,Y,delta): # retailer zero-profit cond.\n",
    "    retailer_res = P_n*C + P_n*Q*C_D - P*Y\n",
    "    return retailer_res\n",
    "\n",
    "@simple\n",
    "def DG_t(DG):\n",
    "    DG_t = DG(-1)\n",
    "    return DG_t\n",
    "\n",
    "@simple\n",
    "def wage_schedule(W,P,N,C,psi_N): # wage schedule target\n",
    "    wage_res = W/P - psi_N*N*C\n",
    "    return wage_res\n",
    "\n",
    "@simple\n",
    "def fiscal(r, Bg,W,P,N):\n",
    "    Tax = r*Bg\n",
    "    return Tax\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Cut to the chase\n",
    "The surest way to obtain the general equilibrium Jacobians is to use the `get_G` convenience function. Notice the `save=True` option. This means that we're saving the HA Jacobians calculated along the way for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "T = 300\n",
    "exogenous = ['rstar', 'A']\n",
    "unknowns = ['Y','P','Q']\n",
    "targets = ['bond_mkt','retailer_res','wage_res']\n",
    "\n",
    "# general equilibrium jacobians\n",
    "block_list = [prices,inflation,markup_p,taylor,labor_supply,wage,dividends,bond_market_clearing,zero_profit_retailer,wage_schedule,DG_t,fiscal,household] \n",
    "G = jac.get_G(block_list, exogenous, unknowns, targets, T, ss, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Results\n",
    "First let's check that we have correctly reconstructed the steps of `jac.get_G`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in G:\n",
    "    for i in G[o]:\n",
    "        assert np.allclose(G[o][i], G2[o][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's consider 20 basis point monetary policy shocks with different persistences and plot the response of inflation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['Y']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'Y response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['P']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'P response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['P_n']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'Pn response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['P_d']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'Pd response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['Q']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'Q response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['C']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'C response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['DG']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'D response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['N']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'N response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['W']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'W response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['markup_p']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'mark-up response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['r']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'r response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['Pi']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'Pi response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rhos = np.array([0.3]) # persistence\n",
    "\n",
    "drstar = -0.002 * rhos ** (np.arange(T)[:, np.newaxis])\n",
    "dpi = (G['Tax']['rstar'] @ drstar)\n",
    "plt.plot(10000 * dpi[:])\n",
    "plt.title(r'Tax response monetary policy shocks')\n",
    "plt.xlabel('quarters')\n",
    "plt.ylabel('bp deviation from ss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
